---
title: "UN Data Pull and Cleaning"
author: "Brian Stacy"
date: "8/14/2020"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.height=7, fig.width=10)

library(tidyverse)
library(here)
library(wbgmaps)
library(wbggeo)
library(ggthemes)
library(Hmisc)
library(httr)
library(patchwork)
library(ggrepel)


#set directories
dir <- here()

raw_dir <- paste(dir, '01_raw_data', sep="/")
output_dir <- paste(dir, '03_output_data', sep="/")


#read list of iso3c codes for matching from UN (https://unstats.un.org/unsd/methodology/m49/)
iso3c <- read_csv(paste(raw_dir,'iso_codes.csv', sep="/"),
                  col_types=list(col_character(), col_character(), col_character()))

span <- c(2004:2019)

#now create dataframe for merging from 2004 to 2019
iso_empty <- bind_rows(replicate(length(span), iso3c, simplify = FALSE), .id='date') %>%
  mutate(date=as.numeric(date)+span[1]-1) %>%
  select(iso3c, date, geoAreaCode) 

```

```{r programs, eval=FALSE, include=FALSE}


#Now map the result
quality = "high"
maps <- wbgmaps::wbgmaps[[quality]]

country_metadata <- wbstats::wbcountries()



spi_mapper  <- function(data, indicator, title) {
  
 indicator<-indicator

 
 
  map_df <- get(data) %>%
    filter(between(date,2014,2019) ) %>%
    filter(goal==indicator) %>%
    group_by(iso3c) %>%
    summarise(ind_quality=mean(ind_quality, na.rm=T)) %>%
    left_join(country_metadata) %>%
    filter(!is.na(region))
  

   p1 <- ggplot() +
    geom_map(data = map_df, aes(map_id = iso3c, fill = ind_quality), map = maps$countries) + 
    geom_polygon(data = maps$disputed, aes(long, lat, group = group, map_id = id), fill = "grey80") + 
    geom_polygon(data = maps$lakes, aes(long, lat, group = group), fill = "white")  +
     geom_path(data = maps$boundaries,
               aes(long, lat, group = group),
               color = "white",
               size = 0.1,
               lineend = maps$boundaries$lineend,
              linetype = maps$boundaries$linetype) +
    scale_x_continuous(expand = c(0, 0), limits = standard_crop_wintri()$xlim) +
    scale_y_continuous(expand = c(0, 0), limits = standard_crop_wintri()$ylim) +
    scale_fill_continuous(

    )  +
    coord_equal() +
    theme_map(base_size=12) +
    labs(
      title=str_wrap(title,100),
      subtitle= 'Data Point is 5 years average since 2019',
      caption = 'Source: UNSD'
    )
  
  #add histogram by region 
  p2 <- map_df %>%
    group_by(region) %>%
    filter(region!='Aggregates') %>%
    mutate(Score=100*mean(ind_quality),
           Label = paste(round(Score,0)) %>%
    ggplot(aes(x=Score, y=region, fill=region)) +
      geom_bar(stat="identity",position='dodge') +
      geom_text(aes(label=Label)) +
      labs(
      title=str_wrap(paste(title, 'By Region', sep=" - "),100),
      caption = 'Source: UNSD',
      subtitle= 'Data Point is 5 years average since 2019'
      ) +
      theme_bw()

  #add histogram by region 
  p3 <- map_df %>%
    group_by(income) %>%
    filter(region!='Aggregates') %>%
    mutate(Score=100*mean(ind_quality),
           Label = paste(round(Score,0)) %>%
    ggplot(aes(x=Score, y=income, fill=income)) +
      geom_bar(stat="identity",position='dodge') +
      geom_text(aes(label=Label)) +
      labs(
      title=str_wrap(paste(title, 'By Income', sep=" - "),100),
      caption = 'Source: UNSD',
      subtitle= 'Data Point is 5 years average since 2019'
      ) +
      theme_bw()  
  # #add line graph over time
  p4 <- get(data)  %>% 
    filter(goal==indicator) %>%
    group_by( date) %>%
    mutate(Score=100*mean(ind_quality, na.rm=T),
           Label = paste(round(Score,0)) %>%
    ungroup() %>%
    ggplot(aes(y=Score, x=date)) +
      geom_point() +
      geom_line(fill='blue') +
      # geom_text_repel(aes(label=Label)) +
      labs(
      title=str_wrap(paste(title, 'By Date', sep=" - "),100),
      caption = 'Source: UNSD'
      ) +
      expand_limits(y=c(0,100)) +
      theme_bw()
      
  print(p1)
  
  print(p2)
  
  print(p3)

  print(p4)

     
}



```


# Introduction

This R Markdown file will do the following:

  1. Download the latest SDG indicator data from UN Stats (https://unstats.un.org/sdgs/indicators/en/#) using their API   
  
  2. Transform the data so that for each indicator we can create a score documenting whether a value exists for the country in a year, whether the value is based on country data, country data adjusted, estimated, or modelled data according the UN Stats metadata. **This will only include tier 1 indicators**.    
  
  3. Combine the resulting data into a single file for use in the Statistical Performance Indicators dashboard and index

# UN Stats Database

Below is a paraphrased description from the UN stats webpage (https://unstats.un.org/sdgs/indicators/indicators-list/):

The global indicator framework for Sustainable Development Goals was developed by the Inter-Agency and Expert Group on SDG Indicators (IAEG-SDGs) and agreed upon at the 48th session of the United Nations Statistical Commission held in March 2017.

The global indicator framework includes 231 unique indicators. Please note that the total number of indicators listed in the global indicator framework of SDG indicators is 247. However, twelve indicators repeat under two or three different targets.

For each value of the indicator, the responsible international agency has been requested to indicate whether the national data were adjusted, estimated, modelled or are the result of global monitoring. The “nature” of the data in the SDG database is determined as follows:


  * Country data (C): Produced and disseminated by the country (including data adjusted by the country to meet international standards);    
  
  * Country data adjusted (CA): Produced and provided by the country, but adjusted by the international agency for international comparability to comply with internationally agreed standards, definitions and classifications;    
  
  * Estimated (E): Estimated based on national data, such as surveys or administrative records, or other sources but on the same variable being estimated, produced by the international agency when country data for some year(s) is not available, when multiple sources exist, or when there are data quality issues;    
  
  * Modelled (M): Modelled by the agency on the basis of other covariates when there is a complete lack of data on the variable being estimated;    
  
  * Global monitoring data (G): Produced on a regular basis by the designated agency for global monitoring, based on country data. There is no corresponding figure at the country level.

# Scoring

For each indicator, we will produce a value for each country with the following coding scheme:    

  * **1 Point**: Indicator exists and the value is based on the **country** data    
  * **0.75 Points**: Indicator exists and the value is based on **country data adjusted**    
  * **0.5 Points**: Indicator exists and the value is based on **estimated or Global Monitoring** data   
  * **0.25 Points**: Indicator exists and the value is based on **modelled** data   
  * **0 Points**: Indicator **does not exists**
  
  
# API

Now we will pull data from the UN Stats API (https://unstats.un.org/SDGAPI/swagger/).  We will keep only the tier 1 indicators

```{r api_indicators}

#get a list of all SDG indicators
indicators_url <- 'https://unstats.un.org/SDGAPI/v1/sdg/Indicator/List'

#bring in the list of indicators
list_df <- jsonlite::fromJSON(indicators_url, flatten = TRUE) %>%
  as_tibble() %>%
  unnest(keep_empty = TRUE) %>%
  filter(tier==1) # keep just the tier 1 indicators

```

```{r api_download, include=FALSE}

# now we will loop through the list of indicators and download the SDG databases

#define function to pull data from UN Stats and return
un_pull <- function(series,start, end) {
  # jsonlite::fromJSON(paste('https://unstats.un.org/SDGAPI/v1/sdg/Series/Data?seriesCode=',series,'&timePeriodStart=',start,'&timePeriodEnd=',end,'&pageSize=10000',sep=""), flatten = TRUE)$data %>%
      jsonlite::fromJSON(paste('https://unstats.un.org/SDGAPI/v1/sdg/Series/Data?seriesCode=',series,'&pageSize=10000',sep=""), flatten = TRUE)$data %>%

    as_tibble() %>%
    mutate(date=timePeriodStart) %>%
    right_join(iso_empty) %>%
    mutate(available=!is.na(value),  #check whether indicator is available
           quality=case_when(
             (available & attributes.Nature=='C') ~ 1,
             (available & attributes.Nature=='CA') ~ 0.75,
             (available & (attributes.Nature=='E' | attributes.Nature=='G')) ~ 0.5,
             (available & attributes.Nature=='M') ~ 0.25,
             !available ~ 0
           )) %>%
    group_by(iso3c, date) %>%
    summarise(ind_value=mean(as.numeric(value), na.rm=T),
              ind_metadata=first(attributes.Nature),
              ind_quality=mean(quality, na.rm=T)
              ) 
}  

#remove this dataframe if it exists
if (exists('un_sdg_df')) {
  rm(un_sdg_df)
}

list_df<- list_df[seq(dim(list_df)[1],1),]

#loop through all sdg indicators and append to a database containing the value, metadata info, and quality measure for each year and couuntry.
for (series in list_df$code1) {
  tryCatch({
  if (!file.exists(paste(raw_dir,'/sdg_data/',series,'.csv',sep=""))) {
    print(series)


  #Sys.sleep(60)
    #create a temporary database that will have the value, metadata info, and quality measure for each year and couuntry.
    indicators_df <- list_df %>%
      filter(code1==series) %>%
      mutate(
      values = map(
        code1,
        un_pull,'2000','2019' )
      ) %>%
      unnest(values) %>%
      select(iso3c, date, goal, target, code, code1, description1, ind_value, ind_metadata, ind_quality) %>%
      write_excel_csv(paste(raw_dir,'/sdg_data/',series,'.csv',sep=""))

  }

}, error=function(e){cat("ERROR :",conditionMessage(e), "\n")})

}




```


```{r save}

for (series in list_df$code1) {
    
  #read in files
  
  temp <- read_csv(paste(raw_dir,'/sdg_data/',series,'.csv',sep=""))
  
  #   #now append it to the overall database
  if (!exists('un_sdg_df')) {
    un_sdg_df <- temp
  } else if (exists('un_sdg_df')) {
    un_sdg_df <- un_sdg_df %>%
      bind_rows(temp)
  }
  
  
}


#save the data file
  
write_excel_csv(un_sdg_df, paste(output_dir, '/un_sdg_df.csv',sep=""))


```

# Summary Statistics by SDG Goal

Below we will produce maps and statistics by region/income group of the SPI Indicators based on the UN SDG database.  This will be done according to SDG goal (1-17)

```{r sdg_goal}

un_sdg_df <- read_csv(paste(output_dir,'/un_sdg_df.csv',sep=""))

spi_mapper('un_sdg_df', '1','Goal 1')
spi_mapper('un_sdg_df', '2','Goal 2')
spi_mapper('un_sdg_df', '3','Goal 3')
spi_mapper('un_sdg_df', '4','Goal 4')
spi_mapper('un_sdg_df', '5','Goal 5')
spi_mapper('un_sdg_df', '6','Goal 6')
spi_mapper('un_sdg_df', '7','Goal 7')
spi_mapper('un_sdg_df', '8','Goal 8')
spi_mapper('un_sdg_df', '9','Goal 9')
spi_mapper('un_sdg_df', '10','Goal 10')
spi_mapper('un_sdg_df', '11','Goal 11')
spi_mapper('un_sdg_df', '12','Goal 12')
spi_mapper('un_sdg_df', '13','Goal 13')
spi_mapper('un_sdg_df', '14','Goal 14')
spi_mapper('un_sdg_df', '15','Goal 15')
spi_mapper('un_sdg_df', '16','Goal 16')
spi_mapper('un_sdg_df', '17','Goal 17')


# stats_fun <- 

```


# Summary Statistics by SDG Group (Social, Economic, Environmental, Institutional)

Below we will produce maps and statistics by region/income group of the SPI Indicators based on the UN SDG database. This will be done by the following classification:

* Social Statistics (SDG goal 1-6)
* Economic Statistics (SDG goal 7-12)
* Environmental Staistics (SDG goal 13-15)
* Institutional Statistics (SDG goal 16-17)




  